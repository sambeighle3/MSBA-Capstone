{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c6fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d21697",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d2da1b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Year'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNonresident_Percentage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Adjust Number_of_Successes based on residency and the actual nonresident percentage\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdjusted_Number_of_Successes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mItem_Description\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistrict\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber_of_Successes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     38\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdjusted_Number_of_Successes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNonresident_Percentage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mwhere(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResidency\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNONRESIDENT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     40\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResidency\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNONRESIDENT\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdjusted_Number_of_Successes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdjusted_Number_of_Successes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:8872\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   8869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   8870\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 8872\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   8873\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   8874\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[0;32m   8875\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   8876\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   8877\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[0;32m   8878\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   8879\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[0;32m   8880\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[0;32m   8881\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[0;32m   8882\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1274\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1274\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[0;32m   1275\u001b[0m         obj,\n\u001b[0;32m   1276\u001b[0m         keys,\n\u001b[0;32m   1277\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   1278\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   1279\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   1280\u001b[0m         observed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m observed,\n\u001b[0;32m   1281\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[0;32m   1282\u001b[0m     )\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Year'"
     ]
    }
   ],
   "source": [
    "# This is for raw data calculations\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory where your files are located\n",
    "input_directory_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\Final Calculation'\n",
    "\n",
    "# Specify the directory where you want to save the new Excel files\n",
    "output_directory_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\Final Calculation'\n",
    "\n",
    "# Get a list of all Excel files in the specified directory\n",
    "file_names = [f for f in os.listdir(input_directory_path) if f.endswith('.xlsx')]\n",
    "\n",
    "# Create an empty list to store DataFrames for each year\n",
    "dfs_by_year = []\n",
    "\n",
    "# Iterate through each file\n",
    "for file_name in file_names:\n",
    "    # Construct the full input file path\n",
    "    input_file_path = os.path.join(input_directory_path, file_name)\n",
    "\n",
    "    # Load the data for the current file\n",
    "    df = pd.read_excel(input_file_path)\n",
    "\n",
    "    # Convert relevant columns to numeric\n",
    "    numeric_columns = ['Number_of_Applications', 'Number_of_Successes', 'Number_of_Points']\n",
    "    df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Calculate Real_Entries\n",
    "    df['Real_Entries'] = df['Number_of_Points'] ** 2 + 1\n",
    "\n",
    "    # Calculate Real_Total_Entries\n",
    "    df['Real_Total_Entries'] = df['Real_Entries'] * df['Number_of_Applications']\n",
    "    \n",
    "    df['Nonresident_Percentage'] = 0.1\n",
    "    \n",
    "    # Adjust Number_of_Successes based on residency and the actual nonresident percentage\n",
    "    df['Adjusted_Number_of_Successes'] = df.groupby(['Item_Description','District','Year'])['Number_of_Successes'].transform('sum')\n",
    "    df['Adjusted_Number_of_Successes'] *= df['Nonresident_Percentage'].where(df['Residency'] == 'NONRESIDENT', 1)\n",
    "    \n",
    "    df.loc[(df['Residency'] == 'NONRESIDENT') & (df['Adjusted_Number_of_Successes'] == 0), 'Adjusted_Number_of_Successes'] = 1\n",
    "    \n",
    "    # Calculate the probability of not drawing any applicant in a single draw\n",
    "    df['Prob_Not_Drawing'] = (df.groupby(['Item_Description','District','Year'])['Real_Total_Entries'].transform('sum') - df['Real_Entries']) / df.groupby(['Item_Description','District','Year'])['Real_Total_Entries'].transform('sum')\n",
    "\n",
    "    # Calculate the probability of not drawing any applicant in all draws\n",
    "    df['Prob_Not_Drawing_All'] = (df['Prob_Not_Drawing'] ** df['Adjusted_Number_of_Successes'])\n",
    "\n",
    "    # Calculate the probability of drawing at least one applicant\n",
    "    df['Prob_Drawing_At_Least_One'] = 1 - df['Prob_Not_Drawing_All']\n",
    "\n",
    "    # Add the processed DataFrame to the list\n",
    "    dfs_by_year.append(df)\n",
    "\n",
    "    # Construct the full output file path\n",
    "    output_file_path = os.path.join(output_directory_path, f'{file_name.split(\".\")[0]}_Processed2.0.xlsx')\n",
    "\n",
    "    # Save the updated DataFrame to the new Excel file\n",
    "    df.to_excel(output_file_path, index=False)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "full_data = pd.concat(dfs_by_year, ignore_index=True)\n",
    "\n",
    "# Display the processed data\n",
    "print(full_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddb622a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Excel file saved at: C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\Final Calculation\\cleaned_final_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the directory where your files are located\n",
    "input_directory_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\Final Calculation\\final_data_includes_missing.xlsx'\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(input_directory_path)\n",
    "\n",
    "# Remove duplicate rows while keeping the first occurrence\n",
    "clean_df = df.drop_duplicates(subset=['Item_Description', 'District', 'Residency', 'Number_of_Points'], keep='first')\n",
    "\n",
    "# Specify the file name for the new Excel file\n",
    "output_file_name = 'cleaned_final_data.xlsx'\n",
    "\n",
    "# Specify the directory where you want to save the new Excel file\n",
    "output_directory_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\Final Calculation'\n",
    "\n",
    "# Full path for the output file\n",
    "output_file_path = output_directory_path + '\\\\' + output_file_name\n",
    "\n",
    "# Save the cleaned DataFrame to a new Excel file\n",
    "clean_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "# Print the path of the new Excel file\n",
    "print(\"New Excel file saved at:\", output_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f81b9ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Number_of_Points Item_Description District    Residency  \\\n",
      "0               0.0  ANTELOPELICENSE   215-20  NONRESIDENT   \n",
      "1               0.0  ANTELOPELICENSE   215-20     RESIDENT   \n",
      "2               0.0  ANTELOPELICENSE   291-20  NONRESIDENT   \n",
      "3               0.0  ANTELOPELICENSE   291-20     RESIDENT   \n",
      "4               0.0  ANTELOPELICENSE   300-20  NONRESIDENT   \n",
      "\n",
      "   Number_of_Applications  Number_of_Successes  Nonresident_Percentage  \\\n",
      "0                  16.299                    4                0.055556   \n",
      "1                  58.990                    4                0.055556   \n",
      "2                   0.000                    1                     NaN   \n",
      "3                  12.305                    1                     NaN   \n",
      "4                  17.027                  248                0.090000   \n",
      "\n",
      "   Real_Entries  Real_Total_Entries  Adjusted_Number_of_Successes  \\\n",
      "0           1.0              16.299                      0.222222   \n",
      "1           1.0              58.990                      4.000000   \n",
      "2           1.0               0.000                           NaN   \n",
      "3           1.0              12.305                      1.000000   \n",
      "4           1.0              17.027                     22.320000   \n",
      "\n",
      "   Prob_Not_Drawing  Prob_Not_Drawing_All  Prob_Drawing_At_Least_One  \n",
      "0          0.999534              0.999897                   0.000103  \n",
      "1          0.999534              0.998139                   0.001861  \n",
      "2          0.998103                   NaN                        NaN  \n",
      "3          0.998103              0.998103                   0.001897  \n",
      "4          0.999821              0.996004                   0.003996  \n"
     ]
    }
   ],
   "source": [
    "# This is for the joined_data from 1000 point tables simulation\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory where your files are located\n",
    "input_directory_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\Final Calculation'\n",
    "\n",
    "# Specify the directory where you want to save the new Excel files\n",
    "output_directory_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\Final Calculation'\n",
    "\n",
    "# Get a list of all Excel files in the specified directory\n",
    "file_names = [f for f in os.listdir(input_directory_path) if f.endswith('.xlsx')]\n",
    "\n",
    "# Create an empty list to store DataFrames for each year\n",
    "dfs_by_year = []\n",
    "\n",
    "# Iterate through each file\n",
    "for file_name in file_names:\n",
    "    # Construct the full input file path\n",
    "    input_file_path = os.path.join(input_directory_path, file_name)\n",
    "\n",
    "    # Load the data for the current file\n",
    "    df = pd.read_excel(input_file_path)\n",
    "\n",
    "    # Convert relevant columns to numeric\n",
    "    numeric_columns = ['Number_of_Applications', 'Number_of_Successes', 'Number_of_Points']\n",
    "    df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Calculate Real_Entries\n",
    "    df['Real_Entries'] = df['Number_of_Points'] ** 2 + 1\n",
    "\n",
    "    # Calculate Real_Total_Entries\n",
    "    df['Real_Total_Entries'] = df['Real_Entries'] * df['Number_of_Applications']\n",
    "    \n",
    "  \n",
    "    \n",
    "    # Adjust Number_of_Successes based on residency and the actual nonresident percentage\n",
    "    df['Adjusted_Number_of_Successes'] = df['Number_of_Successes']\n",
    "    df['Adjusted_Number_of_Successes'] *= df['Nonresident_Percentage'].where(df['Residency'] == 'NONRESIDENT', 1)\n",
    "    \n",
    "    df.loc[(df['Residency'] == 'NONRESIDENT') & (df['Adjusted_Number_of_Successes'] == 0), 'Adjusted_Number_of_Successes'] = 1\n",
    "    \n",
    "    # Calculate the probability of not drawing any applicant in a single draw\n",
    "    df['Prob_Not_Drawing'] = (df.groupby(['Item_Description','District'])['Real_Total_Entries'].transform('sum') - df['Real_Entries']) / df.groupby(['Item_Description','District'])['Real_Total_Entries'].transform('sum')\n",
    "\n",
    "    # Calculate the probability of not drawing any applicant in all draws\n",
    "    df['Prob_Not_Drawing_All'] = (df['Prob_Not_Drawing'] ** df['Adjusted_Number_of_Successes'])\n",
    "\n",
    "    # Calculate the probability of drawing at least one applicant\n",
    "    df['Prob_Drawing_At_Least_One'] = 1 - df['Prob_Not_Drawing_All']\n",
    "\n",
    "    # Add the processed DataFrame to the list\n",
    "    dfs_by_year.append(df)\n",
    "\n",
    "    # Construct the full output file path\n",
    "    output_file_path = os.path.join(output_directory_path, f'{file_name.split(\".\")[0]}_Processed2.0.xlsx')\n",
    "\n",
    "    # Save the updated DataFrame to the new Excel file\n",
    "    df.to_excel(output_file_path, index=False)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "full_data = pd.concat(dfs_by_year, ignore_index=True)\n",
    "\n",
    "# Display the processed data\n",
    "print(full_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df28064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe3f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the 'Updated_Data' file into a DataFrame\n",
    "file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Test Folder\\FWP Model Data.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Fill in the remaining blanks with the provided calculations\n",
    "df['Nonresident_Percentage'] = 0.1\n",
    "\n",
    "# Adjust Number_of_Successes based on residency and the actual nonresident percentage\n",
    "df['Adjusted_Number_of_Successes'] = df.groupby(['Item_Description', 'District', 'Year'])['Number_of_Successes'].transform('sum')\n",
    "df['Adjusted_Number_of_Successes'] *= df['Nonresident_Percentage'].where(df['Residency'] == 'NONRESIDENT', 1)\n",
    "\n",
    "df.loc[(df['Residency'] == 'NONRESIDENT') & (df['Adjusted_Number_of_Successes'] == 0), 'Adjusted_Number_of_Successes'] = 1\n",
    "\n",
    "# Calculate the probability of not drawing any applicant in a single draw\n",
    "df['Prob_Not_Drawing'] = (df.groupby(['Item_Description', 'District', 'Year'])['Real_Total_Entries'].transform('sum') - df['Real_Entries']) / df.groupby(['Item_Description', 'District', 'Year'])['Real_Total_Entries'].transform('sum')\n",
    "\n",
    "# Calculate the probability of not drawing any applicant in all draws\n",
    "df['Prob_Not_Drawing_All'] = (df['Prob_Not_Drawing'] ** df['Adjusted_Number_of_Successes'])\n",
    "\n",
    "# Calculate the probability of drawing at least one applicant\n",
    "df['Prob_Drawing_At_Least_One'] = 1 - df['Prob_Not_Drawing_All']\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Save the updated DataFrame to the same Excel file\n",
    "df.to_excel(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05c1e824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Item_Description District           Residency  Number_of_Points  Year  \\\n",
      "0  ANTELOPEARCHERYONLY   900-21  RESIDENT LANDOWNER                 0  2024   \n",
      "1  ANTELOPEARCHERYONLY   900-21  RESIDENT LANDOWNER                 1  2024   \n",
      "2  ANTELOPEARCHERYONLY   900-21  RESIDENT LANDOWNER                 2  2024   \n",
      "3  ANTELOPEARCHERYONLY   900-21  RESIDENT LANDOWNER                 3  2024   \n",
      "4  ANTELOPEARCHERYONLY   900-21  RESIDENT LANDOWNER                 4  2024   \n",
      "\n",
      "   Number_of_Applications  Number_of_Successes  %_Successful  Real_Entries  \\\n",
      "0                       0                  0.0           0.0             1   \n",
      "1                       5                  5.0         100.0             2   \n",
      "2                       0                  0.0           0.0             5   \n",
      "3                       0                  0.0           0.0            10   \n",
      "4                       0                  0.0           0.0            17   \n",
      "\n",
      "   Nonresident_Percentage  Adjusted_Number_of_Successes  Real_Total_Entries  \\\n",
      "0                     0.1                           5.0                10.0   \n",
      "1                     0.1                           5.0                10.0   \n",
      "2                     0.1                           5.0                10.0   \n",
      "3                     0.1                           5.0                10.0   \n",
      "4                     0.1                           5.0                10.0   \n",
      "\n",
      "   Prob_Not_Drawing  Prob_Not_Drawing_All  Prob_Drawing_At_Least_One  \n",
      "0               0.9               0.59049                    0.40951  \n",
      "1               0.8               0.32768                    0.67232  \n",
      "2               0.5               0.03125                    0.96875  \n",
      "3               0.0               0.00000                    1.00000  \n",
      "4              -0.7              -0.16807                    1.16807  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Calculations for Total Real Total Entries\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the 'Updated_Data' file into a DataFrame\n",
    "file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\2024_Data.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Calculate the probability of not drawing any applicant in a single draw\n",
    "df['Prob_Not_Drawing'] = (df['Real_Total_Entries']- df['Real_Entries']) / df['Real_Total_Entries']\n",
    "\n",
    "# Calculate the probability of not drawing any applicant in all draws\n",
    "df['Prob_Not_Drawing_All'] = (df['Prob_Not_Drawing'] ** df['Adjusted_Number_of_Successes'])\n",
    "\n",
    "# Calculate the probability of drawing at least one applicant\n",
    "df['Prob_Drawing_At_Least_One'] = 1 - df['Prob_Not_Drawing_All']\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Save the updated DataFrame to the same Excel file\n",
    "df.to_excel(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500678c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b5512",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculations data for regression Model\n",
    "# Model Predicting 2024\n",
    "# Model Predicting 2024\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\FWP Regression Model Data with 2024.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Adjust Number_of_Successes based on residency and the actual nonresident percentage\n",
    "df['Adjusted_Number_of_Successes'] = df.groupby(['Item_Description', 'District', 'Year'])['Number_of_Successes'].transform('sum')\n",
    "df['Adjusted_Number_of_Successes'] *= df['Nonresident_Percentage'].where(df['Residency'] == 'NONRESIDENT', 1)\n",
    "\n",
    "df.loc[(df['Residency'] == 'NONRESIDENT') & (df['Adjusted_Number_of_Successes'] == 0), 'Adjusted_Number_of_Successes'] = 1\n",
    "\n",
    "# Additional conditions for 2023/2024\n",
    "for (item, district), subset in df.groupby(['Item_Description', 'District']):\n",
    "    if 2023 in subset['Year'].values and 2024 in subset['Year'].values:\n",
    "        # Check if the Real Total Entries value in 2024 matches 2023\n",
    "        if subset.loc[subset['Year'] == 2024, 'Real_Total_Entries'].values[0] != subset.loc[subset['Year'] == 2023, 'Real_Total_Entries'].values[0]:\n",
    "            # Calculate the probability of not drawing any applicant in a single draw without grouping by\n",
    "            df.loc[(df['Item_Description'] == item) & (df['District'] == district) & (df['Year'] == 2024), 'Prob_Not_Drawing'] = (df['Real_Total_Entries'] - df['Real_Entries']) / df['Real_Total_Entries']\n",
    "\n",
    "# Calculate the probability of not drawing any applicant in all draws\n",
    "df['Prob_Not_Drawing_All'] = (df['Prob_Not_Drawing'] ** df['Adjusted_Number_of_Successes'])\n",
    "\n",
    "# Calculate the probability of drawing at least one applicant\n",
    "df['Prob_Drawing_At_Least_One'] = 1 - df['Prob_Not_Drawing_All']\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Save the updated DataFrame to the same Excel file\n",
    "df.to_excel(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad2736",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b21823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
