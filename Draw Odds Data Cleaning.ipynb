{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7ae497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory where your files are located\n",
    "directory_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw'\n",
    "\n",
    "# Get a list of all Excel files in the specified directory\n",
    "file_names = [f for f in os.listdir(directory_path) if f.endswith('.xlsx')]\n",
    "\n",
    "# Dictionary to store the correct headers for each column\n",
    "correct_headers = {\n",
    "    'Item Type Code - Description': 'Item_Description',\n",
    "    'District': 'District',\n",
    "    'Residency': 'Residency',\n",
    "    '# Points': 'Number_of_Points',\n",
    "    '# Applied': 'Number_of_Applications',\n",
    "    '# Successful': 'Number_of_Successes',\n",
    "    '% Successful': '%_Successful',\n",
    "    'Number of Successes': 'Number_of_Successes',\n",
    "    'Number of Applications': 'Number_of_Applications',\n",
    "    'Number of Points': 'Number_of_Points',\n",
    "    'Item Description': 'Item_Description',\n",
    "}\n",
    "\n",
    "# Function to clean and update headers\n",
    "def clean_and_update_headers(df, file_name):\n",
    "    # Check if any correct headers are missing\n",
    "    missing_headers = [header for header in correct_headers.values() if header not in df.columns]\n",
    "\n",
    "    # Update headers if needed\n",
    "    if missing_headers:\n",
    "        print(f\"Updating headers for file: {file_name}\")\n",
    "        df.columns = [correct_headers.get(col, col) for col in df.columns]\n",
    "\n",
    "        # Save the updated DataFrame to the same Excel file, overwriting the original\n",
    "        df.to_excel(file_path, index=False)\n",
    "    else:\n",
    "        print(f\"Headers are correct for file: {file_name}\")\n",
    "\n",
    "    # Print the headers\n",
    "    print(f\"Headers for file {file_name}:\\n{df.columns}\\n\")\n",
    "\n",
    "# Check and update headers for each file\n",
    "for file_name in file_names:\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(directory_path, file_name)\n",
    "\n",
    "    # Load the data for the current file\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Apply cleaning and header update function\n",
    "    clean_and_update_headers(df, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6708f6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory where your files are located\n",
    "directory_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Original Draw Odd Files\\Fixed Files'\n",
    "\n",
    "# Get a list of all Excel files in the specified directory\n",
    "file_names = [f for f in os.listdir(directory_path) if f.endswith('.xlsx')]\n",
    "\n",
    "# Iterate through each file and remove rows with blank 'Residency' cells\n",
    "for file_name in file_names:\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(directory_path, file_name)\n",
    "\n",
    "    # Load the data for the current file\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Remove rows with blank cells in the 'Residency' column\n",
    "    df = df.dropna(subset=['Residency'])\n",
    "\n",
    "    # Save the updated DataFrame to the same Excel file, overwriting the original\n",
    "    df.to_excel(file_path, index=False)\n",
    "\n",
    "    print(f\"Removed rows with blank 'Residency' cells in file: {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51d6fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory where your files are located\n",
    "directory_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Original Draw Odd Files\\Fixed Files'\n",
    "\n",
    "# Get a list of all Excel files in the specified directory\n",
    "file_names = [f for f in os.listdir(directory_path) if f.endswith('.xlsx')]\n",
    "\n",
    "# Iterate through each file and replace blanks with 0 in 'Number_of_Points' column\n",
    "for file_name in file_names:\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(directory_path, file_name)\n",
    "\n",
    "    # Load the data for the current file\n",
    "    df = pd.read_excel(file_path)\n",
    "  \n",
    "    # Replace blanks with 0 in 'Number_of_Points' column\n",
    "    df['Number_of_Points'].fillna(0, inplace=True)\n",
    "\n",
    "    # Save the updated DataFrame to the same Excel file, overwriting the original\n",
    "    df.to_excel(file_path, index=False)\n",
    "\n",
    "    print(f\"Filled blanks with 0 in 'Number_of_Points' column in file: {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a14a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing Duplicates in 2016\n",
    "import pandas as pd\n",
    "\n",
    "# Read the dataset into a pandas DataFrame\n",
    "file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\Cleaned_Data_2_21.xlsx'  # Adjust the file path and name as needed\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Filter rows where the year is not 2016\n",
    "df_not_2016 = df[df['Year'] != 2016]\n",
    "\n",
    "# Filter rows where the year is 2016 and drop duplicates\n",
    "df_2016 = df[df['Year'] == 2016].drop_duplicates(keep='first')\n",
    "\n",
    "# Concatenate the filtered DataFrames\n",
    "df_cleaned = pd.concat([df_not_2016, df_2016])\n",
    "\n",
    "# Save the cleaned DataFrame back to your desired location\n",
    "cleaned_file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\Cleaned_Data_2_21_noduplicates.xlsx'  # Adjust the file path and name as needed\n",
    "df_cleaned.to_excel(cleaned_file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c77ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Blanks for Second 0\n",
    "import pandas as pd\n",
    "\n",
    "# Read the dataset into a pandas DataFrame\n",
    "file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\Cleaned_Data_2_21_noduplicates.xlsx'  # Adjust the file path and name as needed\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "# Group by unique combinations of Item Description, District, Residency, and Year\n",
    "grouped = df.groupby(['Item_Description', 'District', 'Residency', 'Year'])\n",
    "\n",
    "# Function to replace the second '0' with 'Blank'\n",
    "def replace_second_zero(group):\n",
    "    zero_indices = group.index[group['Number_of_Points'] == 0]\n",
    "    if len(zero_indices) >= 2:\n",
    "        group = group.copy()\n",
    "        group['Number_of_Points'] = group['Number_of_Points'].astype(object)  # Convert dtype to object\n",
    "        group.loc[zero_indices[1], 'Number_of_Points'] = 'Blank'\n",
    "    return group\n",
    "\n",
    "# Apply the function to each group\n",
    "df_cleaned = grouped.apply(replace_second_zero)\n",
    "\n",
    "# Save the cleaned DataFrame back to your desired location\n",
    "cleaned_file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\Cleaned_Data_2_21_w_Blanks.xlsx'  # Adjust the file path and name as needed\n",
    "df_cleaned.to_excel(cleaned_file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ec8db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-20 points\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the data from Excel file\n",
    "file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Original Draw Odd Files\\Fixed Files\\2023_ELK_GOOD_Cleaned_Processed2.0.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Assuming your existing DataFrame is named 'df'\n",
    "# If it has a different name, replace 'df' with the actual name\n",
    "existing_columns = ['Item_Description', 'District', 'Residency', 'Number_of_Points', 'Year', 'Number_of_Applications', 'Number_of_Successes', '%_Successful', ]\n",
    "\n",
    "# Get unique combinations of existing data\n",
    "unique_combinations = df[['Item_Description', 'District', 'Residency', 'Year']].drop_duplicates()\n",
    "\n",
    "# Create a template DataFrame with Number of Points ranging from 0 to 21 for each unique combination\n",
    "template_data = []\n",
    "for index, row in unique_combinations.iterrows():\n",
    "    item_desc = row['Item_Description']\n",
    "    district = row['District']\n",
    "    residency = row['Residency']\n",
    "    year = row['Year']\n",
    "    for points in range(0, 21):\n",
    "        # Append values only to 'Item_Description', 'District', 'Residency', 'Year', and 'Number_of_Points'\n",
    "        template_data.append([item_desc, district, residency, points, year] + [np.nan] * (len(existing_columns)-5))\n",
    "\n",
    "template_df = pd.DataFrame(template_data, columns=existing_columns)\n",
    "\n",
    "# Merge the template DataFrame with your existing DataFrame\n",
    "merged_df = pd.merge(template_df, df, how='left', on=['Item_Description', 'District', 'Residency', 'Year', 'Number_of_Points'])\n",
    "\n",
    "# Save the updated DataFrame to a new Excel file\n",
    "output_file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Original Draw Odd Files\\Fixed Files\\2023_ELK_GOOD_Cleaned_Processed_20.xlsx'\n",
    "merged_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(merged_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6326b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding every year for every permit with 0s for deer and elk ,antelope and moose sheep goat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the data from Excel file\n",
    "file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\FWP Data_2_21_Cleaned.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Assuming your existing DataFrame is named 'df'\n",
    "# If it has a different name, replace 'df' with the actual name\n",
    "existing_columns = ['Item_Description', 'District', 'Residency', 'Number_of_Points', 'Year', 'Number_of_Applications', 'Number_of_Successes', '%_Successful']\n",
    "\n",
    "# Get unique combinations of existing data\n",
    "unique_combinations = df[['Item_Description', 'District', 'Residency']].drop_duplicates()\n",
    "\n",
    "# Create a template DataFrame with Number of Points ranging from 0 to 20 for each unique combination and year\n",
    "template_data = []\n",
    "for index, row in unique_combinations.iterrows():\n",
    "    item_desc = row['Item_Description']\n",
    "    district = row['District']\n",
    "    residency = row['Residency']\n",
    "    for year in range(2006, 2024):\n",
    "        for points in range(0, 21):\n",
    "            template_data.append([item_desc, district, residency, points, year])\n",
    "\n",
    "template_df = pd.DataFrame(template_data, columns=['Item_Description', 'District', 'Residency', 'Number_of_Points', 'Year'])\n",
    "\n",
    "# Merge the template DataFrame with your existing DataFrame\n",
    "merged_df = pd.merge(template_df, df, how='left', on=['Item_Description', 'District', 'Residency', 'Number_of_Points', 'Year'])\n",
    "\n",
    "# Fill missing values with 0\n",
    "merged_df.fillna(0, inplace=True)\n",
    "\n",
    "# Define output file paths with specific names\n",
    "deer_elk_file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\deer_elk_data.xlsx'\n",
    "moose_goat_sheep_file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\moose_goat_sheep_data.xlsx'\n",
    "antelope_file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\antelope_data.xlsx'\n",
    "\n",
    "# Filter rows based on item descriptions\n",
    "deer_elk_df = merged_df[merged_df['Item_Description'].isin(['DEERPERMIT', 'ELKPERMIT', 'ELKBLICENSE', 'DEERBLICENSE'])]\n",
    "moose_goat_sheep_df = merged_df[merged_df['Item_Description'].isin(['MOOSELICENSE', 'GOATLICENSE', 'SHEEPLICENSE'])]\n",
    "antelope_df = merged_df[merged_df['Item_Description'].isin(['ANTELOPELICENSE', 'ANTELOPEBLICENSE', 'ANTELOPEARCHERYONLY'])]\n",
    "\n",
    "# Save the filtered DataFrames to the specified file paths\n",
    "deer_elk_df.to_excel(deer_elk_file_path, index=False)\n",
    "moose_goat_sheep_df.to_excel(moose_goat_sheep_file_path, index=False)\n",
    "antelope_df.to_excel(antelope_file_path, index=False)\n",
    "\n",
    "print(\"Filtered data saved to separate Excel files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d21697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Original Draw Odd Files\\Fixed Files\\2023_ELK_Cleaned.xlsx'\n",
    "\n",
    "# Load the 'Updated_Data' file into a DataFrame\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Calculate Real_Entries only for rows where it is blank\n",
    "df.loc[df['Real_Entries'].isna(), 'Real_Entries'] = df['Number_of_Points'] ** 2 + 1\n",
    "\n",
    "# Calculate Real_Total_Entries only for rows where it is blank\n",
    "df.loc[df['Real_Total_Entries'].isna(), 'Real_Total_Entries'] = df['Real_Entries'] * df['Number_of_Applications']\n",
    "\n",
    "# Set Number_of_Applications, Number_of_Successes, %_Successful to 0 for rows where Real_Total_Entries is blank\n",
    "df.loc[df['Real_Total_Entries'].isna(), ['Number_of_Applications', 'Number_of_Successes', '%_Successful']] = 0\n",
    "\n",
    "# Set Real_Total_Entries to 0 for rows where it is blank\n",
    "df.loc[df['Real_Total_Entries'].isna(), 'Real_Total_Entries'] = 0\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Save the updated DataFrame to the same Excel file\n",
    "df.to_excel(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4260ade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the 'Updated_Data' file into a DataFrame\n",
    "file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Original Draw Odd Files\\Fixed Files\\2023_ELK_Cleaned.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Fill in the remaining blanks with the provided calculations\n",
    "df['Nonresident_Percentage'] = 0.1\n",
    "\n",
    "# Adjust Number_of_Successes based on residency and the actual nonresident percentage\n",
    "df['Adjusted_Number_of_Successes'] = df.groupby(['Item_Description', 'District', 'Year'])['Number_of_Successes'].transform('sum')\n",
    "df['Adjusted_Number_of_Successes'] *= df['Nonresident_Percentage'].where(df['Residency'] == 'NONRESIDENT', 1)\n",
    "\n",
    "df.loc[(df['Residency'] == 'NONRESIDENT') & (df['Adjusted_Number_of_Successes'] == 0), 'Adjusted_Number_of_Successes'] = 1\n",
    "\n",
    "# Calculate the probability of not drawing any applicant in a single draw\n",
    "df['Prob_Not_Drawing'] = (df.groupby(['Item_Description', 'District', 'Year'])['Real_Total_Entries'].transform('sum') - df['Real_Entries']) / df.groupby(['Item_Description', 'District', 'Year'])['Real_Total_Entries'].transform('sum')\n",
    "\n",
    "# Calculate the probability of not drawing any applicant in all draws\n",
    "df['Prob_Not_Drawing_All'] = (df['Prob_Not_Drawing'] ** df['Adjusted_Number_of_Successes'])\n",
    "\n",
    "# Calculate the probability of drawing at least one applicant\n",
    "df['Prob_Drawing_At_Least_One'] = 1 - df['Prob_Not_Drawing_All']\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Save the updated DataFrame to the same Excel file\n",
    "df.to_excel(file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e744931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing 's' and 'first choice applicant text in columns'\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# File path for the original Excel file\n",
    "original_file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\FWP Regression Model Data2.0.xlsx'\n",
    "\n",
    "# Read Excel file into DataFrame\n",
    "df = pd.read_excel(original_file_path)\n",
    "\n",
    "# Remove lowercase \"s\" from Resident column\n",
    "df['Residency'] = df['Residency'].str.replace('^s', '', regex=True)\n",
    "\n",
    "# Remove anything after the district number\n",
    "df['District'] = df['District'].str.extract(r'(\\d+-\\d+)')\n",
    "\n",
    "# File path for the new Excel file\n",
    "new_file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\Cleaned_Data_2_14.xlsx'\n",
    "\n",
    "# Save the modified DataFrame to a new Excel file\n",
    "df.to_excel(new_file_path, index=False)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf5d649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49947e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting data combined to only permits that can pass through the function.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the data from the Excel file\n",
    "file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\FWP Data_2_21_Cleaned.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Find unique combinations that have data for the year 2023\n",
    "valid_combinations = df[df['Year'] == 2023][['Item_Description', 'District']].drop_duplicates()\n",
    "\n",
    "# Filter the original dataframe to keep only rows with valid combinations\n",
    "filtered_df = df.merge(valid_combinations, on=['Item_Description', 'District'], how='inner')\n",
    "\n",
    "# Identify removed combinations (combinations not in valid_combinations)\n",
    "removed_combinations = df[~df[['Item_Description', 'District']].apply(tuple, axis=1).isin(valid_combinations.apply(tuple, axis=1))][['Item_Description', 'District']].drop_duplicates()\n",
    "\n",
    "# Print and save removed combinations to a new Excel file\n",
    "print(\"Combinations Removed:\")\n",
    "print(removed_combinations)\n",
    "removed_combinations.to_excel('removed_combinations.xlsx', index=False)\n",
    "\n",
    "# Write filtered data to a new Excel file with a specific name\n",
    "filtered_file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\filtered_data.xlsx'\n",
    "filtered_df.to_excel(filtered_file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02e1cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure if this one works\n",
    "import pandas as pd\n",
    "\n",
    "# Read the data from the Excel file\n",
    "file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\FWP Data_2_21_Cleaned.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Find unique combinations that have data for the year 2023\n",
    "valid_combinations = df[df['Year'] == 2023][['Item_Description', 'District']].drop_duplicates()\n",
    "\n",
    "# Filter the original dataframe to keep only rows with valid combinations\n",
    "filtered_df = df.merge(valid_combinations, on=['Item_Description', 'District'], how='inner')\n",
    "\n",
    "# Identify removed combinations (combinations not in valid_combinations)\n",
    "removed_combinations = df[~df[['Item_Description', 'District']].apply(tuple, axis=1).isin(valid_combinations.apply(tuple, axis=1))][['Item_Description', 'District']].drop_duplicates()\n",
    "\n",
    "# Print and save removed combinations to a new Excel file\n",
    "print(\"Combinations Removed:\")\n",
    "print(removed_combinations)\n",
    "removed_combinations.to_excel('removed_combinations.xlsx', index=False)\n",
    "\n",
    "# Print valid combinations (combinations not removed)\n",
    "print(\"\\nUnique Combinations Not Removed:\")\n",
    "print(valid_combinations)\n",
    "\n",
    "# Write filtered data to a new Excel file with a specific name\n",
    "filtered_file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\filtered_data.xlsx'\n",
    "filtered_df.to_excel(filtered_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41bac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now data of only 5 plus years\n",
    "import pandas as pd\n",
    "\n",
    "# Read the data from the Excel file\n",
    "file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\filtered_data.xlsx'\n",
    "filtered_df = pd.read_excel(file_path)\n",
    "\n",
    "# Group by Item_Description and District, and filter out combinations with less than 5 years of data\n",
    "grouped_df = filtered_df.groupby(['Item_Description', 'District']).filter(lambda x: x['Year'].nunique() >= 5)\n",
    "\n",
    "# Identify removed combinations due to less than 5 years of data\n",
    "removed_combinations_5_years = filtered_df[~filtered_df.index.isin(grouped_df.index)][['Item_Description', 'District']].drop_duplicates()\n",
    "\n",
    "# Print and save removed combinations due to less than 5 years of data\n",
    "print(\"Combinations Removed due to Less than 5 Years of Data:\")\n",
    "print(removed_combinations_5_years)\n",
    "removed_combinations_5_years.to_excel('removed_combinations_5_years.xlsx', index=False)\n",
    "\n",
    "# Write filtered data to a new Excel file with a specific name\n",
    "new_filtered_file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\filtered_data_with_5_years.xlsx'\n",
    "grouped_df.to_excel(new_filtered_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1172d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data from the Excel file\n",
    "file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\filtered_data_with_5_years.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Create a DataFrame with all unique combinations of \"Item_Description\", \"District\", \"Number_of_Points\", and \"Year\"\n",
    "unique_combinations = df[['Item_Description', 'District', 'Number_of_Points', 'Year']].drop_duplicates()\n",
    "\n",
    "# Create a DataFrame for RESIDENT rows with 0 values for other columns\n",
    "resident_df = unique_combinations.assign(Residency='RESIDENT', Number_of_Successes=0, Real_Entries=0, Real_Total_Entries=0, Nonresident_Percentage=0, Adjusted_Number_of_Successes=0)\n",
    "\n",
    "# Create a DataFrame for NONRESIDENT rows with 0 values for other columns\n",
    "nonresident_df = unique_combinations.assign(Residency='NONRESIDENT', Number_of_Successes=0, Real_Entries=0, Real_Total_Entries=0, Nonresident_Percentage=0, Adjusted_Number_of_Successes=0)\n",
    "\n",
    "# Concatenate the resident and nonresident DataFrames\n",
    "filled_df = pd.concat([resident_df, nonresident_df])\n",
    "\n",
    "# Merge with the original DataFrame to fill in the existing data\n",
    "merged_df = filled_df.merge(df, on=['Item_Description', 'District', 'Number_of_Points', 'Year', 'Residency'], how='left')\n",
    "\n",
    "# Fill missing values with 0\n",
    "merged_df.fillna(0, inplace=True)\n",
    "\n",
    "# Write the merged DataFrame to a new Excel file\n",
    "output_file_path = r'C:\\Users\\Sam Beighle\\Documents\\Capstone - FWP Draw\\Final Calculation Folder\\filled_data.xlsx'\n",
    "merged_df.to_excel(output_file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce63e0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
